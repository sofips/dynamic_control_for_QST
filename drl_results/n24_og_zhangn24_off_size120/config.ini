[experiment]
new_experiment = True
experiment_alias = n24_og_zhang
experiment_description = Optuna optimization with full reward and oaps actions for 32 spins chain. Running on Serafin.

[system_parameters]
chain_length = 24
tstep_length = 0.15
tolerance = 0.05
max_t_steps = 120
field_strength = 100
coupling = 1
n_actions = 16
action_set = zhang

[learning_parameters]
prioritized_experience_replay = False
number_of_features = 48
number_of_episodes = 50000
learning_rate = 0.01
gamma = 0.95
replace_target_iter = 200
memory_size = 40000
batch_size = 32
epsilon = 0.99
epsilon_increment = 0.0001
fc1_dims = 120
dropout = 0.0
reward_function = original

[tags]
reward_function = original
prioritized = not prioritized
mlflow.note.content = Optuna optimization with full reward and oaps actions for 32 spins chain. Running on Serafin.
action set = zhang
chain_length = 24

