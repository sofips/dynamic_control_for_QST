[experiment]
new_experiment = True
experiment_alias = opt_for_n12_oaps_noise_per/trial_46
experiment_description = New set of experiments. Noisy steps. PER. We optimize over eps increment, fc1dims and                         learning_rate using avg of last 100 max_fids as metric. Site reward now working                           Standarization of results.

[system_parameters]
chain_length = 12
tstep_length = 0.15
tolerance = 0.05
max_t_steps = 60
field_strength = 100
coupling = 1
n_actions = 13
action_set = oaps

[learning_parameters]
prioritized_experience_replay = True
number_of_features = 24
number_of_episodes = 50000
learning_rate = 8.748276772729786e-05
gamma = 0.95
replace_target_iter = 200
memory_size = 40000
batch_size = 32
epsilon = 0.99
epsilon_increment = 0.0053678796824324585
fc1_dims = 155
fc2_dims = 120
dropout = 0.0
reward_function = site evolution

[tags]
reward_function = site evolution
prioritized = prioritized
mlflow.note.content = New set of experiments. Noisy steps. PER. We optimize over eps increment, fc1dims and                         learning_rate using avg of last 100 max_fids as metric. Site reward now working                           Standarization of results.
action set = oaps
chain_length = 12

